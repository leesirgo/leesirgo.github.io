{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 写在前面\n",
    "请记住，统计就是通过样本去推断总体。<br>\n",
    "<img src=image\\数据概率.png>\n",
    "\n",
    "林德伯格和莱维20世纪20年代证明了**“中心极限定理”**的存在性，使不同统计分布（二项分布、卡方分布、t分布、F分布等）都最终“皈依”为正态分布（即，**正态逼近原理**）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计学术语\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli试验\n",
    "仅有结果的重复独立试验被成为Bernoulli试验。发生或不发生，成功或失败。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 偏差和误差\n",
    "**偏差**：以相同的方式影响所有测量值，将它们推向同一方向。例如，称秤的时候将拇指按在重物上，将只会加大重量；<br>\n",
    "**误差，也叫残差**：随着不同次的测量而变化，有时向上有时向下。误差=实际-预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相关系数 r\n",
    "相关系数越介于-1~1之间，接近于1，变量间的关系就越强。r=1被称为完全相关。<br>\n",
    "相关度量的是相互关系，并不等于因果关系。<br>\n",
    "<img src=image\\相关系数.jpg>\n",
    "**相关系数的计算**<br>\n",
    "将因变量、自变量都转换为标准单位后的乘积的平均数就是相关系数。<br>\n",
    "1. 相关系数是标准化后的计算结果，它不受尺度变化的影响\n",
    "2. 相关系数是标准化后的计算结果，x与y的相关系数等于y与x的相关系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 离散分布和连续分布\n",
    "**离散型随机变量（discrete random variable）**：取值是可数的个值的随机变量，整数。 比如投掷一枚骰子的朝上的点数，可能是1,2,3,4,5,6；比如南京大学四食堂吃饭的人数，可能是0,1,2···。其图像**通常是光滑曲线上独立的散点，没有概率密度函数，只有概率质量函数（Probability Mass Function）。** <br>\n",
    "**对于一个离散型变量，其值仅可相差确定的量**。例如两个家庭在人数上仅可相差0，1，2。 <br>\n",
    "离散变量落在某个点上的概率就等于其在概率质量函数（可理解为直方图）对应的纵值。\n",
    "\n",
    "**连续型随机变量（continuous random variable）**：取值是一个区间中的任意一点（也就是不可数）的随机变量，可能为任意小数。比如身高。其图像**通常是条光滑的曲线，有概率密度函数（Probability Distribution Function）** <br>\n",
    "连续变量落在某个区间的概率等于这个区间在概率密度曲线下面的面积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 离散型随机变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二项分布binnomial distribution\n",
    "<img src=image\\二项分布.png>\n",
    "二项分布常用符合B(n,p)、Bin(n,p)来表示，n代表试验次数，p代表每次进行Bernoulli试验成功的概率。二项分布的取名源于该分布和二项式展开的系数有关；<br>\n",
    "\n",
    "**判定标准**：<br>\n",
    "1. 试验次数n已经固定\n",
    "2. 每次试验都是Bernoulli试验，即每次试验都只有两种可能的结果\n",
    "3. 每次试验成功的概率相等，概率恒定不变，不是指成功概率为50%\n",
    "\n",
    "**应用**：<br>\n",
    "**假如你哪天抛硬币连续三次抛出了正面朝上**，很兴奋，你想知道今天的手气到底有多好？！也就是说，你想知道这个事件发生的概率是多少，当然我相信你也能计算出来，但其实你大可不必亲自动手计算，因为它是满足**二项分布**的，你可以直接查表或者**用excel(BINOM.DIST函数)、R、Python等工具直接输入“试验次数3次，单次成功概率0.5”就可以直接获得概率计算结果了**。这就是方程化的好处。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多项分布 multinoial distribution\n",
    "多项分布常用M(n;p1,p2,p3,p4,p5,……)来表示，n代表试验次数，p代表每次试验出现各种结果对应的概率。<br>\n",
    "多项分布的每次试验有多种可能的结果；<br>\n",
    "\n",
    "**判定标准**：<br>\n",
    "\n",
    "\n",
    "**应用**：<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 泊松分布 Possion distribution\n",
    "首先，泊松分布是一个典型的离散概率分布，而且是不对称分布，它在右边有一个长长的尾巴。<br>\n",
    "<img src=image\\典型泊松分布.jpg>\n",
    "其次，泊松分布是用差分方程建立模型推导出来的 [泊松分布的来源—公式推导—应用 ](http://blog.csdn.net/ningyaliuhebei/article/details/46409215)<br>\n",
    "<img src=image\\泊松分布推导.jpg><img src=image\\泊松分布公式.jpg>\n",
    "还有，泊松是二项模型的一种极限。二项分布在n很大，p很小时，可以用泊松分布算二项分布的概率。**便说一句高斯模型也是二项的极限，同时也是泊松的一种极限形式**。\n",
    "\n",
    "**判定标准**：<br>\n",
    "1. 事情是独立事件\n",
    "2. 在任意相同的时间范围内，事件发生的概率相同\n",
    "3. 你想知道某个时间范围内，发生这件事情X次的概率是多大<br>\n",
    "\n",
    "**应用：泊松分布用于衡量某种事件在一定期间出现的数目的概率,只能用来计算次数**<br>\n",
    "泊松分布适合于描述单位时间内随机事件发生的次数的概率分布，据说是**交通规划里面必用的一个分布**。如某一服务设施在一定时间内受到的服务请求的次数，电话交换机接到呼叫的次数、汽车站台的候客人数、机器出现的故障数、自然灾害发生的次数、DNA序列的变异数、放射性原子核的衰变数等等。<br>\n",
    "possion分布最早提出好像是一军营士兵被马踏到的人数；这2分钟内点进帖子的人数；2分钟内看完点赞的人数都是服从possion分布。比如你想知道一天内中奖的次数，一个月内某机器损坏的次数等，这时候就可以用泊松分布轻松搞定！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 超几何分布\n",
    "超结合分布和二项分布比较相似，二项分布每次实验完全一样，而超几何分布前一次的实验结果会影响后面的实验结果。简单地讲，二项分布抽取之后放回元素，而**超几何分布是无放回的抽取**。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 连续型随机变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正态分布 normal distribution，也叫高斯分布 Gaussian distribution，也叫μ分布\n",
    "正态分布通常用N(μ,σ)或者N(μ,σ^2)表示，N即为normal的意思，μ为总体均值，σ（读sigma）为标准差，σ^2为方差（即标准差的平方，是不是叫“差方”更好记）。<br>\n",
    "正态分布是许多统计方法的基础。\n",
    "\n",
    "**正态分布的概率密度函数形状特征：**<br>\n",
    "1. μ决定它的位置，σ决定它的幅度。μ=0，σ=1是标准正态分布（standard normal distribution）;\n",
    "2. 对称分布，关于μ对称，在μ±σ处有拐点，形状呈中间高两边低的钟形曲线；\n",
    "3. μ、σ不同就是另一个正态分布。\n",
    "<img src=image\\正态分布公式.jpg>\n",
    "<img src=image\\正态分布.jpg>\n",
    "\n",
    "**如何确定数据是否正态分布：**<br>\n",
    "1. 图形感受法：建立直方图或者枝干图，看图像的形状是否类似正太曲线，既土墩形或者钟形，并且两端对称。 \n",
    "2. 计算区间x±s，x±2s，x±3s，看落在区间的百分比是否近似于68%，95%，100%。（切比雪夫法则和经验法则） \n",
    "3. 求IQR和标准差s，计算IQR/s，如若是正态分布，则IQR/s≈1.3.\n",
    "4. 建立正态概率图，如果近似正态分布，点会落在一条直线上。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卡方分布 chi-square distribution\n",
    "卡方分布由阿贝(Abbe)于1863年首先提出的，后来由海尔墨特(Hermert)和现代统计学的奠基人之一的卡·皮尔逊(C K．Pearson)分别于1875年和1900年推导出来，是统计学中的一个非常有用的著名分布。<br>\n",
    "**定义：**n个服从标准正态分布的随机变量的平方和的分布规律。其中，参数n称为自由度（即样本中能独立或能自由变化的自变量的个数，称为自由度。<br>\n",
    "\n",
    "**卡方分布的概率密度函数的形状特征：**\n",
    "1. 随着自由度参数n增大，卡方分布趋近于正态分布\n",
    "2. 随着自由度参数n增大，卡方分布向正无穷方向延伸（因为平方值越来越大），分布图也越来越低阔。\n",
    "3. 不同自由度决定了不同的卡方分布（自由度不同就是不同的卡方分布），自由度越小，分布约偏斜。\n",
    "\n",
    "<img src=image\\卡方分布.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t分布，或称为“学生分布” student distribution\n",
    "之所以叫t分布，是因为提出者Gosset（戈赛特）用t来表示这个分量，而且发表有关论文时用假名字Student。<br>\n",
    "**定义：**假设X服从标准正态分布N（0,1），Y服从χ2（n）分布，那么Z=X/sqrt(Y/n)的分布称为自由度为n的t分布,记为 Z～t(n)。<br>\n",
    "\n",
    "**t分布的概率密度函数的形状特征：**\n",
    "1. t分布**类似标准正态分布，但是中间瘦一些，而且尾巴长一些；**<br>\n",
    "2. 自由度df越小，分布曲线越低平；自由度df越大，分布曲线越接近标准正态分布（μ分布）。\n",
    "<img src=image\\t分布.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F分布 \n",
    "F分布是1924年英国统计学家R.A.Fisher费舍尔提出，并以其姓氏的第一个字母命名的。<br>\n",
    "**定义：**假设X服从自由度为k1的卡方分布，Y服从自由度为k2的卡方分布，这2个独立的卡方分布被各自的自由度除以后的比率这一统计量的分布就叫做F分布。\n",
    "\n",
    "**F分布的性质：**\n",
    "1. F分布是一种非对称分布；\n",
    "2. F分布有两个自由度；\n",
    "3. 不同自由度就是不同的F分布;\n",
    "4. 当第二个自由度相同时，第一个自由度越小，峰越靠近左边。\n",
    "<img src=image\\F分布.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 点估计和区间估计\n",
    "**点估计**：用一个估计量来近似总体参数（更绝对）；<br>\n",
    "**区间估计**：用一个区间来近似总体参数，认为该区间很可能包含总体参数（留有余地）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 置信区间和置信度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，从点估计、区间估计的定义中可以明显看出，**只有区间估计才有置信区间、置信度这么一说**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**误区注意点**<br>\n",
    "1. 假如由一个样本数据得到总体参数的**一个95%置信区间**，不能认为该区间就有95%的概率覆盖总体参数。这是错误的！因为，置信度95%仅仅描述用来构造该区间上下界的统计量覆盖总体参数的概率。也就是说，**正确的理解为：无穷次重复抽样所得到的所有区间中大约有95%包含参数；再换种说法，如果我们不厌其烦地抽样本算区间，得到了很多很多置信区间。那么在这些置信区间中，有95%的置信区间能覆盖到该区间**。\n",
    "2. 根据置信度的计算公式可知，**置信度是一个包含样本总量的参数，样本量对置信度有很大影响**。意义：针对同一个意见调查，第一拨人调查了10000个人，得到支持率比例为70%，第二拨人只调查了50个人，同样得到支持率比例为70%，它们的置信区间计算结果将都是（0.691，0.709），但是置信区间却相去甚远，**前者为95置信度，后者的置信度却只有1%**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 假设检验\n",
    "### 假设检验的术语和思路\n",
    "**理论基础：**许多情况下，企图肯定什么事物都很难，然而否定却要相对容易的多。从哲学观点来说，**全称命题都只能被否证，而不能被证明！**<br>\n",
    "**假设检验都是以否定原假设为目标。**如果否定不了，那就说明证据不足，无法否定原假设，但不能说明原假设正确。<br>\n",
    "**假设检验=反证法+小概率事情**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**原假设，也叫零假设**，是对总体参数做出的一个尝试性假设。<br>\n",
    "**备选假设**，定义的一个和原假设完全对立的假设。<br>\n",
    "**思路：**假设检验就是通过样本数据对两个对立假设进行检验。透露一点，这里的**备选假设**才是真正希望得到支持的结论，而**零假设**是企图拒绝的量。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 假设检验的三种显著水平\n",
    "事先规定的概率称为显著水平 significant level，通常用字母α表示，有的软件用Sig表示。通常，假设检验有0.1%、1%、5%三种显著水平，这是自己根据实际问题的需求来确定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 假设检验的三种检验类型\n",
    "**双侧检验**：对于居民用电的额定电压是220V，高于此值或低于此值均不符合居民用电标准，非“常态”设置为双侧检验形式比较好；<br>\n",
    "**左侧检验**：对于食品的保质期应该大于或等于某个数值，小于保质期就会出问题，此时非“常态”设置为左侧检验比较好<br>\n",
    "**右侧检验**：对于人均收入差距，应该在合理范围内波动，不能超过某个设置数值，此时非“常态”设置为右侧检验比较好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 假设检验的两类错误\n",
    "**第一类错误**：在零假设正确时，小概率事件还是可能发生，这种拒绝了正确零假设的错误通常被称为第一类错误。<br>\n",
    "**第二类错误**：在备选假设正确时，却没能拒绝零假设的错误，这叫第二类错误。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归和分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归、分类的定义及区别\n",
    "建立自变量和响应变量之间关系的过程就叫做**回归或分类**，二者的区别在于**因变量的性质**。当因变量为**数量**变量时，叫做**回归regression**；当因变量为**名义**变量（也叫定性变量、分类变量）时，叫做**分类classification**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定量变量回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性回归之最小二乘法 least squares regression\n",
    "首先，数量属于数值，其拟合模型建立过程叫回归。没毛病。<br>\n",
    "其次，**最小二乘法**线性回归就是寻找一条直线，使得所有点到该直线的垂直距离的平方和最小。最小：**距离最小**，为了减少在因变量方向的误差，也叫**残差平方和最小**；二乘：**古汉语“二乘”是平方的疑似**。<br>\n",
    "<img src=image\\最小二乘法.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性回归之多元回归 multiple regression\n",
    "多元回归和一个变量回归类似，只是变量个数增加了，对对计算机来说没有太大区别。<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 名义变量（定性、分类）回归——分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### “是与否”两个定性变量的回归（分类）-logistic回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic回归又称logistic回归分析，是**一种广义的线性回归分析模型**，常用于数据挖掘，疾病自动诊断，经济预测等领域。例如，探讨引发疾病的危险因素，并根据危险因素预测疾病发生的概率等。以胃癌病情分析为例，选择两组人群，一组是胃癌组，一组是非胃癌组，两组人群必定具有不同的体征与生活方式等。因此因变量就为是否胃癌，值为“是”或“否”，**自变量就可以包括很多了，如年龄、性别、饮食习惯、幽门螺杆菌感染等**。自变量既可以是连续的，也可以是分类的。然后通过logistic回归分析，可以得到自变量的权重，从而可以大致了解到底哪些因素是胃癌的危险因素。同时根据该权值可以根据危险因素预测一个人患癌症的可能性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多个定性变量的回归（分类）-线性判别分析\n",
    "判别分析和决策树都是分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 现代分类和回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树\n",
    "决策树是很多现代分类和回归方法的基础。\n",
    "<img src=image\\决策树.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树更符合人类思考的习惯，符合条件为yes，不符合条件为no。一般按照yes往左，no往右的习惯。<br>\n",
    "评价模型预测好坏的一个准则为**标准化均方误差 normalized mean squares error,NMSE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合算法之Boosting方法\n",
    "Boosting方法是基于决策树方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合算法之随机森林random forests方法\n",
    "随机森林方法也是基于决策树方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 支持向量机support vector machine，SVM\n",
    "**支持向量机方法不是基于决策树方法，而是源于数学模型**。<br>\n",
    "该方法之所以叫支持向量机，**是因为确定一个分割超平面的不是所有的点，而是与超平面最近的若干点，这些点称为“支持向量”（空间中的点都是向量）**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉验证\n",
    "对于一个数据可能有很多模型来拟合，如何衡量和比较模型的精度呢。<br>\n",
    "**将部分数据留作模型的验证**，这个方法很客观，大家都能接受。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多元分析——降维处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从一堆相互关联的数据中找出一两个有代表意义的指标，就是**降维**。数据越相关，降维效果越好。**注意，如果各个变量都独立，主成分分析、因子分析这些多元分析方法是没有意义的。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主成分分析\n",
    "原理上说，主成分分析是寻找椭球的所有主轴。所以，原来有几个变量就有几个主成分<br>\n",
    "数学上用**解数据相关矩阵的特征值**来寻找主成分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因子分析\n",
    "因子分析方法实际上是主成分分析的推广。不同的是，因子分析是事先确定要找多少个成分。所以，从数学模型本身来说，必须先确定因子个数，但很多统计软件默认选择了。<br>\n",
    "此外，因子分析的计算过程也比主成分分析更复杂。比如，多了**因子旋转、因子载荷**等概念。<br>\n",
    "总的来说，主成分分析、因子分析都依赖于原始变量，都是在对原始进行分析，因此**原始变量的选取很关键**。<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚类分析\n",
    "**聚类分析的关键在于度量距离的远近**。注意，聚类分析不需要事先假定有多少类，完全可以按照数据本身的规律来分类。<br>\n",
    "\n",
    "**点间距离**：欧式距离、平方欧式距离、Chebychev距离、Minkovski距离等；<br>\n",
    "<img src=image\\点间距离.jpg>\n",
    "**类间距离**：最短距离法、最长距离法、重心法、类平均法等。\n",
    "<img src=image\\类间距离.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K均值聚类k-means cluster，也叫快速聚类\n",
    "通常，**K均值聚类需要事先确定分类个数**（打脸了）。\n",
    "**思路**：先假定把观测值分成多少类（假定K类），然后以k个点为“种子”，按照它们的距离远近把所有点分成K类，再以这K类的均值（重心）为新的“种子”再重新分类。如此下去，知道收敛或达到预定目标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分层聚类hierarchical cluster\n",
    "**分层聚类不需要事先确定分类个数**。<br>\n",
    "**思路**：起初，有多少点就是多少类；然后，先把最近的两类合并为一类，每一步就少一类；最后，只有一大类。想要几类自己选。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 时间序列\n",
    "时间序列也是某种回归模型，但是它和别的回归有很大区别，区别在于**时间序列是用同一个变量过去的观测值来预测其未来的观测值**；**经典的回归分析**是建立因变量与自变量关系的模型，用自变量来预测因变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
